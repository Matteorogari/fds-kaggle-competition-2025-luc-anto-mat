\section{Methodological Analysis and Results Summary}
\subsection{Performance and Feature Impact}
The analysis confirmed a direct relationship between the \textbf{richness of strategic features} and prediction performance. The \textbf{Strategic Set (17 Features)} yielded the best result (Log Loss $0.347578$), significantly outperforming simpler feature sets (refer to Table \ref{tab:performance} in the Appendix).
\subsection{Stacking Ensemble Role (Condensed)}
The Tier-1 Meta-Model (XGBoost) was employed primarily to \textbf{balance linear and non-linear predictive signals}. The ensemble's effectiveness stems from using robust \textbf{Linear Models (LR)} as the stable base (majority weight), while \textbf{Boosting Models} refined predictions by correcting complex classification errors (Table \ref{tab:weights}). This structure validates the \textbf{Stacking Ensemble} architecture.
\setlength{\parindent}{0pt}
\paragraph{Meta-Model Selection:}
For less complex inputs (Restricted Set), a simpler \textbf{Logistic Regression (LR Meta)} was found to be optimal, indicating that the added complexity of XGBoost is only justified for richer feature sets.
\subsection{Classification Threshold Calibration}
The \textbf{optimal classification threshold} was set at $\mathbf{0.466}$ (lower than the neutral $0.5$). This adjustment was crucial to maximize overall accuracy, compensating for the aggregated model's slight tendency to be conservative in predicting Player 1's victory.
\section{Conclusions}
Maximum accuracy ($85.26\%$) in the Pok√©mon battle prediction task was achieved by integrating three methodological elements: 
\textbf{Domain-specific feature engineering} (e.g., type advantage), use of a \textbf{Stacking Ensemble} to combine linear and non-linear signals,\textbf{Threshold calibration} ($\mathbf{0.466}$).
This analysis validates the hypothesis that complex strategic features provide essential incremental predictive value that cannot be substituted by simpler features based solely on aggregated base stat differences.
